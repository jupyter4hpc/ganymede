{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.insert(0,'/soft/datascience/Balsam/0.3.5.1/env/lib/python3.6/site-packages/')\n",
    "sys.path.insert(0,'/gpfs/mira-home/keceli/ffn/keceli_ffn/')\n",
    "sys.path.insert(0,'/soft/datascience/tensorflow/tf1.13/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow is not installed: \n",
      "  Uncomment the lines in the next cell and execute them to install a new conda environment \n",
      "  and a Jupyter kernel. After the kernel is created, refresh the webpage.\n",
      "  Then, you should see jhub_tensorflow kernel, in the `Kernel/Change kernel` menu on top.\n",
      "  \n",
      "  \n",
      "Pandas is not installed: \n",
      "  Uncomment the lines in the next cell and execute them to install a new conda environment \n",
      "  and a Jupyter kernel. After the kernel is created, refresh the webpage.\n",
      "  Then, you should see jhub_tensorflow kernel, in the `Kernel/Change kernel` menu on top.\n",
      "  \n",
      "  \n",
      "Matplotlib is not installed: \n",
      "  Uncomment the lines in the next cell and execute them to install a new conda environment \n",
      "  and a Jupyter kernel. After the kernel is created, refresh the webpage.\n",
      "  Then, you should see jhub_tensorflow kernel, in the `Kernel/Change kernel` menu on top.\n",
      "  \n",
      "  \n"
     ]
    }
   ],
   "source": [
    "missing_modules = \"\"\"\n",
    "  Uncomment the lines in the next cell and execute them to install a new conda environment \n",
    "  and a Jupyter kernel. After the kernel is created, refresh the webpage.\n",
    "  Then, you should see jhub_tensorflow kernel, in the `Kernel/Change kernel` menu on top.\n",
    "  \n",
    "  \"\"\"\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "except:\n",
    "    print('Tensorflow is not installed:', missing_modules)\n",
    "try:\n",
    "    import pandas as pd\n",
    "except:\n",
    "    print('Pandas is not installed:', missing_modules)\n",
    "try:\n",
    "    import matplotlib\n",
    "except:\n",
    "    print('Matplotlib is not installed:', missing_modules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "\n\nIMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE!\n\nImporting the multiarray numpy extension module failed.  Most\nlikely you are trying to import a failed build of numpy.\nHere is how to proceed:\n- If you're working with a numpy git repository, try `git clean -xdf`\n  (removes all files not under version control) and rebuild numpy.\n- If you are simply trying to use the numpy version that you have installed:\n  your installation is broken - please reinstall numpy.\n- If you have already reinstalled and that did not fix the problem, then:\n  1. Check that you are using the Python you expect (you're using /opt/anaconda3/bin/python),\n     and that you have no directories in your PATH or PYTHONPATH that can\n     interfere with the Python and numpy versions you're trying to use.\n  2. If (1) looks fine, you can open a new issue at\n     https://github.com/numpy/numpy/issues.  Please include details on:\n     - how you installed Python\n     - how you installed numpy\n     - your operating system\n     - whether or not you have multiple versions of Python installed\n     - if you built from source, your compiler versions and ideally a build log\n\n     Note: this error has many possible causes, so please don't comment on\n     an existing issue about this - open a new one instead.\n\nOriginal error was: No module named 'numpy.core._multiarray_umath'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/soft/datascience/tensorflow/tf1.13/numpy/core/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmultiarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/soft/datascience/tensorflow/tf1.13/numpy/core/multiarray.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moverrides\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_multiarray_umath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/soft/datascience/tensorflow/tf1.13/numpy/core/overrides.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m from numpy.core._multiarray_umath import (\n\u001b[0m\u001b[1;32m      7\u001b[0m     add_docstring, implement_array_function, _get_implementing_args)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy.core._multiarray_umath'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-d6579f534729>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/soft/datascience/tensorflow/tf1.13/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# pylint: disable=g-bad-import-order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m  \u001b[0;31m# pylint: disable=unused-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/soft/datascience/tensorflow/tf1.13/tensorflow/python/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;31m# pylint: disable=wildcard-import,g-bad-import-order,g-import-not-at-top\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/soft/datascience/tensorflow/tf1.13/numpy/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_distributor_init\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/soft/datascience/tensorflow/tf1.13/numpy/core/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0mOriginal\u001b[0m \u001b[0merror\u001b[0m \u001b[0mwas\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \"\"\" % (sys.executable, exc)\n\u001b[0;32m---> 71\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0menvkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menv_added\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: \n\nIMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE!\n\nImporting the multiarray numpy extension module failed.  Most\nlikely you are trying to import a failed build of numpy.\nHere is how to proceed:\n- If you're working with a numpy git repository, try `git clean -xdf`\n  (removes all files not under version control) and rebuild numpy.\n- If you are simply trying to use the numpy version that you have installed:\n  your installation is broken - please reinstall numpy.\n- If you have already reinstalled and that did not fix the problem, then:\n  1. Check that you are using the Python you expect (you're using /opt/anaconda3/bin/python),\n     and that you have no directories in your PATH or PYTHONPATH that can\n     interfere with the Python and numpy versions you're trying to use.\n  2. If (1) looks fine, you can open a new issue at\n     https://github.com/numpy/numpy/issues.  Please include details on:\n     - how you installed Python\n     - how you installed numpy\n     - your operating system\n     - whether or not you have multiple versions of Python installed\n     - if you built from source, your compiler versions and ideally a build log\n\n     Note: this error has many possible causes, so please don't comment on\n     an existing issue about this - open a new one instead.\n\nOriginal error was: No module named 'numpy.core._multiarray_umath'\n"
     ]
    }
   ],
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 1\n",
    "## Create a new conda environment\n",
    "#!conda create -y -n jhub_tensorflow\n",
    "\n",
    "## Step 2\n",
    "## After activating the environment, install the modules tou want.\n",
    "## You need to install jupyter nb_conda ipykernel modules as well.\n",
    "## This part can take a long time, take a coffee break\n",
    "#!source activate jhub_tensorflow; conda install -y jupyter nb_conda ipykernel tensorflow matplotlib pandas\n",
    "\n",
    "## Step 3\n",
    "## Install Jupyter kernel\n",
    "#!source activate jhub_tensorflow; python -m ipykernel install --user --name jhub_tensorflow\n",
    "\n",
    "## You can repeat Step 2, whenever you need to install a new module to the same kernel.\n",
    "##!source activate jhub_tensorflow; conda install -y newmodule\n",
    "## You can omit jupyter, nb_conda, ipykernel as you have already installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 7s 116us/sample - loss: 0.4716 - acc: 0.8606\n",
      "10000/10000 [==============================] - 1s 89us/sample - loss: 0.2319 - acc: 0.9333\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.226439</td>\n",
       "      <td>0.934167</td>\n",
       "      <td>8.985000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.005648</td>\n",
       "      <td>0.001602</td>\n",
       "      <td>0.975859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.215710</td>\n",
       "      <td>0.933000</td>\n",
       "      <td>7.371000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.226165</td>\n",
       "      <td>0.933000</td>\n",
       "      <td>8.590250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.227933</td>\n",
       "      <td>0.933500</td>\n",
       "      <td>9.190500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.229208</td>\n",
       "      <td>0.934750</td>\n",
       "      <td>9.533500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.231852</td>\n",
       "      <td>0.937000</td>\n",
       "      <td>10.120000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Loss  Accuracy       Time\n",
       "count  6.000000  6.000000   6.000000\n",
       "mean   0.226439  0.934167   8.985000\n",
       "std    0.005648  0.001602   0.975859\n",
       "min    0.215710  0.933000   7.371000\n",
       "25%    0.226165  0.933000   8.590250\n",
       "50%    0.227933  0.933500   9.190500\n",
       "75%    0.229208  0.934750   9.533500\n",
       "max    0.231852  0.937000  10.120000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A simple test based on the Tensorflow tutorial: https://www.tensorflow.org/tutorials\n",
    "# Run a single epoch for mnist, should take about 10 seconds.\n",
    "\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import numpy as np\n",
    "import sys\n",
    "import datetime\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(32, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "start = time.time()\n",
    "model.fit(x_train, y_train, epochs=1)\n",
    "runtime = time.time() - start\n",
    "loss, acc = model.evaluate(x_test, y_test)\n",
    "\n",
    "# Record the versions, runtime and model metrics into a csv file.\n",
    "record = f'{datetime.datetime.now()},{sys.version.split()[0]},{tf.__version__},{np.__version__},{loss:3f},{acc:.3f},{runtime:.3f}\\n'\n",
    "csvfile = '/lus/theta-fs0/projects/datascience/jupyterhub/tensorflow.csv'\n",
    "with open(csvfile, 'a') as f:\n",
    "        f.write(record)\n",
    "\n",
    "# Read csv file into a Pandas dataframe and print min,max, mean and standard deviation values.\n",
    "import pandas as pd\n",
    "df = pd.read_csv(csvfile)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fa8580060f0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRMQhFOgiIg6hQBcRcYj/BUJnQ/V2g4swAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# A simple plot of accuracy, loss, and runtime.\n",
    "%matplotlib inline\n",
    "df.Accuracy.plot(label='Accuracy')\n",
    "df.Loss.plot()\n",
    "ax = df.Time.plot()\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Python_version</th>\n",
       "      <th>Tensorflow_version</th>\n",
       "      <th>Numpy_version</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-07-05 21:50:54.707166</td>\n",
       "      <td>3.6.8</td>\n",
       "      <td>1.13.1</td>\n",
       "      <td>1.16.2</td>\n",
       "      <td>0.226852</td>\n",
       "      <td>0.933</td>\n",
       "      <td>9.644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-07-05 21:51:39.828420</td>\n",
       "      <td>3.6.8</td>\n",
       "      <td>1.13.1</td>\n",
       "      <td>1.16.2</td>\n",
       "      <td>0.225936</td>\n",
       "      <td>0.935</td>\n",
       "      <td>9.202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-07-05 22:03:57.582148</td>\n",
       "      <td>3.6.8</td>\n",
       "      <td>1.13.1</td>\n",
       "      <td>1.16.2</td>\n",
       "      <td>0.229273</td>\n",
       "      <td>0.934</td>\n",
       "      <td>8.394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-07-05 22:07:14.543136</td>\n",
       "      <td>3.6.8</td>\n",
       "      <td>1.13.1</td>\n",
       "      <td>1.16.2</td>\n",
       "      <td>0.229013</td>\n",
       "      <td>0.933</td>\n",
       "      <td>10.120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-07-05 22:27:40.154685</td>\n",
       "      <td>3.6.8</td>\n",
       "      <td>1.13.1</td>\n",
       "      <td>1.16.2</td>\n",
       "      <td>0.215710</td>\n",
       "      <td>0.937</td>\n",
       "      <td>9.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019-07-14 18:21:11.680041</td>\n",
       "      <td>3.6.8</td>\n",
       "      <td>1.13.1</td>\n",
       "      <td>1.16.2</td>\n",
       "      <td>0.231852</td>\n",
       "      <td>0.933</td>\n",
       "      <td>7.371</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Date Python_version Tensorflow_version Numpy_version  \\\n",
       "0  2019-07-05 21:50:54.707166          3.6.8             1.13.1        1.16.2   \n",
       "1  2019-07-05 21:51:39.828420          3.6.8             1.13.1        1.16.2   \n",
       "2  2019-07-05 22:03:57.582148          3.6.8             1.13.1        1.16.2   \n",
       "3  2019-07-05 22:07:14.543136          3.6.8             1.13.1        1.16.2   \n",
       "4  2019-07-05 22:27:40.154685          3.6.8             1.13.1        1.16.2   \n",
       "5  2019-07-14 18:21:11.680041          3.6.8             1.13.1        1.16.2   \n",
       "\n",
       "       Loss  Accuracy    Time  \n",
       "0  0.226852     0.933   9.644  \n",
       "1  0.225936     0.935   9.202  \n",
       "2  0.229273     0.934   8.394  \n",
       "3  0.229013     0.933  10.120  \n",
       "4  0.215710     0.937   9.179  \n",
       "5  0.231852     0.933   7.371  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
