{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installed kernelspec jhub_myenv in /gpfs/mira-home/gurunathgr/.local/share/jupyter/kernels/jhub_myenv\r\n"
     ]
    }
   ],
   "source": [
    "!source activate;python -m ipykernel install --user --name jhub_myenv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Jupyter Tensorflow </center></h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This shows the tensorflow jupyter notebook that uses interactive widgets to get the input for trainging the sample dynamically from the user, that makes it easy for the user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <--> Step 1: Create a new conda environment if it not installed before hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/gurunathgr/.conda/envs/jhub_tensorflow\n",
      "\n",
      "\n",
      "\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "#\n",
      "# To activate this environment, use\n",
      "#\n",
      "#     $ conda activate jhub_tensorflow\n",
      "#\n",
      "# To deactivate an active environment, use\n",
      "#\n",
      "#     $ conda deactivate\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda create -y -n jhub_tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <--> Step 2 : After activating the environment, install the modules you want. You need to install jupyter nb_conda ipykernel modules as well.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/gurunathgr/.conda/envs/jhub_tensorflow\n",
      "\n",
      "  added / updated specs:\n",
      "    - ipykernel\n",
      "    - jupyter\n",
      "    - matplotlib\n",
      "    - nb_conda\n",
      "    - pandas\n",
      "    - tensorflow\n",
      "\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  _libgcc_mutex      pkgs/main/linux-64::_libgcc_mutex-0.1-main\n",
      "  _tflow_select      pkgs/main/linux-64::_tflow_select-2.3.0-mkl\n",
      "  absl-py            pkgs/main/linux-64::absl-py-0.9.0-py37_0\n",
      "  astunparse         pkgs/main/noarch::astunparse-1.6.3-py_0\n",
      "  attrs              pkgs/main/noarch::attrs-19.3.0-py_0\n",
      "  backcall           pkgs/main/noarch::backcall-0.2.0-py_0\n",
      "  blas               pkgs/main/linux-64::blas-1.0-mkl\n",
      "  bleach             pkgs/main/noarch::bleach-3.1.5-py_0\n",
      "  blinker            pkgs/main/linux-64::blinker-1.4-py37_0\n",
      "  brotlipy           pkgs/main/linux-64::brotlipy-0.7.0-py37h7b6447c_1000\n",
      "  c-ares             pkgs/main/linux-64::c-ares-1.15.0-h7b6447c_1001\n",
      "  ca-certificates    pkgs/main/linux-64::ca-certificates-2020.6.24-0\n",
      "  cachetools         pkgs/main/noarch::cachetools-4.1.0-py_1\n",
      "  certifi            pkgs/main/linux-64::certifi-2020.6.20-py37_0\n",
      "  cffi               pkgs/main/linux-64::cffi-1.14.0-py37he30daa8_1\n",
      "  chardet            pkgs/main/linux-64::chardet-3.0.4-py37_1003\n",
      "  click              pkgs/main/noarch::click-7.1.2-py_0\n",
      "  cryptography       pkgs/main/linux-64::cryptography-2.9.2-py37h1ba5d50_0\n",
      "  cycler             pkgs/main/linux-64::cycler-0.10.0-py37_0\n",
      "  dbus               pkgs/main/linux-64::dbus-1.13.16-hb2f20db_0\n",
      "  decorator          pkgs/main/noarch::decorator-4.4.2-py_0\n",
      "  defusedxml         pkgs/main/noarch::defusedxml-0.6.0-py_0\n",
      "  entrypoints        pkgs/main/linux-64::entrypoints-0.3-py37_0\n",
      "  expat              pkgs/main/linux-64::expat-2.2.9-he6710b0_2\n",
      "  fontconfig         pkgs/main/linux-64::fontconfig-2.13.0-h9420a91_0\n",
      "  freetype           pkgs/main/linux-64::freetype-2.10.2-h5ab3b9f_0\n",
      "  gast               pkgs/main/noarch::gast-0.3.3-py_0\n",
      "  glib               pkgs/main/linux-64::glib-2.65.0-h3eb4bd4_0\n",
      "  google-auth        pkgs/main/noarch::google-auth-1.17.2-py_0\n",
      "  google-auth-oauth~ pkgs/main/noarch::google-auth-oauthlib-0.4.1-py_2\n",
      "  google-pasta       pkgs/main/noarch::google-pasta-0.2.0-py_0\n",
      "  grpcio             pkgs/main/linux-64::grpcio-1.27.2-py37hf8bcb03_0\n",
      "  gst-plugins-base   pkgs/main/linux-64::gst-plugins-base-1.14.0-hbbd80ab_1\n",
      "  gstreamer          pkgs/main/linux-64::gstreamer-1.14.0-hb31296c_0\n",
      "  h5py               pkgs/main/linux-64::h5py-2.10.0-py37hd6299e0_1\n",
      "  hdf5               pkgs/main/linux-64::hdf5-1.10.6-hb1b8bf9_0\n",
      "  icu                pkgs/main/linux-64::icu-58.2-he6710b0_3\n",
      "  idna               pkgs/main/noarch::idna-2.10-py_0\n",
      "  importlib-metadata pkgs/main/linux-64::importlib-metadata-1.7.0-py37_0\n",
      "  importlib_metadata pkgs/main/noarch::importlib_metadata-1.7.0-0\n",
      "  intel-openmp       pkgs/main/linux-64::intel-openmp-2020.1-217\n",
      "  ipykernel          pkgs/main/linux-64::ipykernel-5.3.2-py37h5ca1d4c_0\n",
      "  ipython            pkgs/main/linux-64::ipython-7.16.1-py37h5ca1d4c_0\n",
      "  ipython_genutils   pkgs/main/linux-64::ipython_genutils-0.2.0-py37_0\n",
      "  ipywidgets         pkgs/main/noarch::ipywidgets-7.5.1-py_0\n",
      "  jedi               pkgs/main/linux-64::jedi-0.17.1-py37_0\n",
      "  jinja2             pkgs/main/noarch::jinja2-2.11.2-py_0\n",
      "  jpeg               pkgs/main/linux-64::jpeg-9b-h024ee3a_2\n",
      "  jsonschema         pkgs/main/linux-64::jsonschema-3.2.0-py37_1\n",
      "  jupyter            pkgs/main/linux-64::jupyter-1.0.0-py37_7\n",
      "  jupyter_client     pkgs/main/noarch::jupyter_client-6.1.6-py_0\n",
      "  jupyter_console    pkgs/main/noarch::jupyter_console-6.1.0-py_0\n",
      "  jupyter_core       pkgs/main/linux-64::jupyter_core-4.6.3-py37_0\n",
      "  keras-preprocessi~ pkgs/main/noarch::keras-preprocessing-1.1.0-py_1\n",
      "  kiwisolver         pkgs/main/linux-64::kiwisolver-1.2.0-py37hfd86e86_0\n",
      "  ld_impl_linux-64   pkgs/main/linux-64::ld_impl_linux-64-2.33.1-h53a641e_7\n",
      "  libedit            pkgs/main/linux-64::libedit-3.1.20191231-h14c3975_1\n",
      "  libffi             pkgs/main/linux-64::libffi-3.3-he6710b0_2\n",
      "  libgcc-ng          pkgs/main/linux-64::libgcc-ng-9.1.0-hdf63c60_0\n",
      "  libgfortran-ng     pkgs/main/linux-64::libgfortran-ng-7.3.0-hdf63c60_0\n",
      "  libpng             pkgs/main/linux-64::libpng-1.6.37-hbc83047_0\n",
      "  libprotobuf        pkgs/main/linux-64::libprotobuf-3.12.3-hd408876_0\n",
      "  libsodium          pkgs/main/linux-64::libsodium-1.0.18-h7b6447c_0\n",
      "  libstdcxx-ng       pkgs/main/linux-64::libstdcxx-ng-9.1.0-hdf63c60_0\n",
      "  libuuid            pkgs/main/linux-64::libuuid-1.0.3-h1bed415_2\n",
      "  libxcb             pkgs/main/linux-64::libxcb-1.14-h7b6447c_0\n",
      "  libxml2            pkgs/main/linux-64::libxml2-2.9.10-he19cac6_1\n",
      "  markdown           pkgs/main/linux-64::markdown-3.1.1-py37_0\n",
      "  markupsafe         pkgs/main/linux-64::markupsafe-1.1.1-py37h14c3975_1\n",
      "  matplotlib         pkgs/main/linux-64::matplotlib-3.2.2-0\n",
      "  matplotlib-base    pkgs/main/linux-64::matplotlib-base-3.2.2-py37hef1b27d_0\n",
      "  mistune            pkgs/main/linux-64::mistune-0.8.4-py37h14c3975_1001\n",
      "  mkl                pkgs/main/linux-64::mkl-2020.1-217\n",
      "  mkl-service        pkgs/main/linux-64::mkl-service-2.3.0-py37he904b0f_0\n",
      "  mkl_fft            pkgs/main/linux-64::mkl_fft-1.1.0-py37h23d657b_0\n",
      "  mkl_random         pkgs/main/linux-64::mkl_random-1.1.1-py37h0573a6f_0\n",
      "  nb_conda           pkgs/main/linux-64::nb_conda-2.2.1-py37_0\n",
      "  nb_conda_kernels   pkgs/main/linux-64::nb_conda_kernels-2.2.3-py37_0\n",
      "  nbconvert          pkgs/main/linux-64::nbconvert-5.6.1-py37_1\n",
      "  nbformat           pkgs/main/noarch::nbformat-5.0.7-py_0\n",
      "  ncurses            pkgs/main/linux-64::ncurses-6.2-he6710b0_1\n",
      "  notebook           pkgs/main/linux-64::notebook-6.0.3-py37_0\n",
      "  numpy              pkgs/main/linux-64::numpy-1.18.5-py37ha1c710e_0\n",
      "  numpy-base         pkgs/main/linux-64::numpy-base-1.18.5-py37hde5b4d6_0\n",
      "  oauthlib           pkgs/main/noarch::oauthlib-3.1.0-py_0\n",
      "  openssl            pkgs/main/linux-64::openssl-1.1.1g-h7b6447c_0\n",
      "  opt_einsum         pkgs/main/noarch::opt_einsum-3.1.0-py_0\n",
      "  packaging          pkgs/main/noarch::packaging-20.4-py_0\n",
      "  pandas             pkgs/main/linux-64::pandas-1.0.5-py37h0573a6f_0\n",
      "  pandoc             pkgs/main/linux-64::pandoc-2.10-0\n",
      "  pandocfilters      pkgs/main/linux-64::pandocfilters-1.4.2-py37_1\n",
      "  parso              pkgs/main/noarch::parso-0.7.0-py_0\n",
      "  pcre               pkgs/main/linux-64::pcre-8.44-he6710b0_0\n",
      "  pexpect            pkgs/main/linux-64::pexpect-4.8.0-py37_1\n",
      "  pickleshare        pkgs/main/linux-64::pickleshare-0.7.5-py37_1001\n",
      "  pip                pkgs/main/linux-64::pip-20.1.1-py37_1\n",
      "  prometheus_client  pkgs/main/noarch::prometheus_client-0.8.0-py_0\n",
      "  prompt-toolkit     pkgs/main/noarch::prompt-toolkit-3.0.5-py_0\n",
      "  prompt_toolkit     pkgs/main/noarch::prompt_toolkit-3.0.5-0\n",
      "  protobuf           pkgs/main/linux-64::protobuf-3.12.3-py37he6710b0_0\n",
      "  ptyprocess         pkgs/main/linux-64::ptyprocess-0.6.0-py37_0\n",
      "  pyasn1             pkgs/main/noarch::pyasn1-0.4.8-py_0\n",
      "  pyasn1-modules     pkgs/main/noarch::pyasn1-modules-0.2.7-py_0\n",
      "  pycparser          pkgs/main/noarch::pycparser-2.20-py_2\n",
      "  pygments           pkgs/main/noarch::pygments-2.6.1-py_0\n",
      "  pyjwt              pkgs/main/linux-64::pyjwt-1.7.1-py37_0\n",
      "  pyopenssl          pkgs/main/noarch::pyopenssl-19.1.0-py_1\n",
      "  pyparsing          pkgs/main/noarch::pyparsing-2.4.7-py_0\n",
      "  pyqt               pkgs/main/linux-64::pyqt-5.9.2-py37h05f1152_2\n",
      "  pyrsistent         pkgs/main/linux-64::pyrsistent-0.16.0-py37h7b6447c_0\n",
      "  pysocks            pkgs/main/linux-64::pysocks-1.7.1-py37_1\n",
      "  python             pkgs/main/linux-64::python-3.7.7-hcff3b4d_5\n",
      "  python-dateutil    pkgs/main/noarch::python-dateutil-2.8.1-py_0\n",
      "  pytz               pkgs/main/noarch::pytz-2020.1-py_0\n",
      "  pyzmq              pkgs/main/linux-64::pyzmq-19.0.1-py37he6710b0_1\n",
      "  qt                 pkgs/main/linux-64::qt-5.9.7-h5867ecd_1\n",
      "  qtconsole          pkgs/main/noarch::qtconsole-4.7.5-py_0\n",
      "  qtpy               pkgs/main/noarch::qtpy-1.9.0-py_0\n",
      "  readline           pkgs/main/linux-64::readline-8.0-h7b6447c_0\n",
      "  requests           pkgs/main/noarch::requests-2.24.0-py_0\n",
      "  requests-oauthlib  pkgs/main/noarch::requests-oauthlib-1.3.0-py_0\n",
      "  rsa                pkgs/main/noarch::rsa-4.0-py_0\n",
      "  scipy              pkgs/main/linux-64::scipy-1.5.0-py37h0b6359f_0\n",
      "  send2trash         pkgs/main/linux-64::send2trash-1.5.0-py37_0\n",
      "  setuptools         pkgs/main/linux-64::setuptools-49.2.0-py37_0\n",
      "  sip                pkgs/main/linux-64::sip-4.19.8-py37hf484d3e_0\n",
      "  six                pkgs/main/noarch::six-1.15.0-py_0\n",
      "  sqlite             pkgs/main/linux-64::sqlite-3.32.3-h62c20be_0\n",
      "  tensorboard        pkgs/main/noarch::tensorboard-2.2.1-pyh532a8cf_0\n",
      "  tensorboard-plugi~ pkgs/main/noarch::tensorboard-plugin-wit-1.6.0-py_0\n",
      "  tensorflow         pkgs/main/linux-64::tensorflow-2.2.0-mkl_py37h6e9ce2d_0\n",
      "  tensorflow-base    pkgs/main/linux-64::tensorflow-base-2.2.0-mkl_py37hd506778_0\n",
      "  tensorflow-estima~ pkgs/main/noarch::tensorflow-estimator-2.2.0-pyh208ff02_0\n",
      "  termcolor          pkgs/main/linux-64::termcolor-1.1.0-py37_1\n",
      "  terminado          pkgs/main/linux-64::terminado-0.8.3-py37_0\n",
      "  testpath           pkgs/main/noarch::testpath-0.4.4-py_0\n",
      "  tk                 pkgs/main/linux-64::tk-8.6.10-hbc83047_0\n",
      "  tornado            pkgs/main/linux-64::tornado-6.0.4-py37h7b6447c_1\n",
      "  traitlets          pkgs/main/linux-64::traitlets-4.3.3-py37_0\n",
      "  urllib3            pkgs/main/noarch::urllib3-1.25.9-py_0\n",
      "  wcwidth            pkgs/main/noarch::wcwidth-0.2.5-py_0\n",
      "  webencodings       pkgs/main/linux-64::webencodings-0.5.1-py37_1\n",
      "  werkzeug           pkgs/main/noarch::werkzeug-1.0.1-py_0\n",
      "  wheel              pkgs/main/linux-64::wheel-0.34.2-py37_0\n",
      "  widgetsnbextension pkgs/main/linux-64::widgetsnbextension-3.5.1-py37_0\n",
      "  wrapt              pkgs/main/linux-64::wrapt-1.12.1-py37h7b6447c_1\n",
      "  xz                 pkgs/main/linux-64::xz-5.2.5-h7b6447c_0\n",
      "  zeromq             pkgs/main/linux-64::zeromq-4.3.2-he6710b0_2\n",
      "  zipp               pkgs/main/noarch::zipp-3.1.0-py_0\n",
      "  zlib               pkgs/main/linux-64::zlib-1.2.11-h7b6447c_3\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attrs-19.3.0         | 40 KB     | ##################################### | 100% \n",
      "oauthlib-3.1.0       | 91 KB     | ##################################### | 100% \n",
      "defusedxml-0.6.0     | 23 KB     | ##################################### | 100% \n",
      "testpath-0.4.4       | 82 KB     | ##################################### | 100% \n",
      "python-dateutil-2.8. | 215 KB    | ##################################### | 100% \n",
      "qtpy-1.9.0           | 38 KB     | ##################################### | 100% \n",
      "traitlets-4.3.3      | 140 KB    | ##################################### | 100% \n",
      "ipywidgets-7.5.1     | 104 KB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: - b'Enabling nb_conda_kernels...\\nStatus: enabled\\n'\n",
      "| b'Enabling notebook extension nb_conda/main...\\n      - Validating: \\x1b[32mOK\\x1b[0m\\nEnabling tree extension nb_conda/tree...\\n      - Validating: \\x1b[32mOK\\x1b[0m\\nEnabling: nb_conda\\n- Writing config: /home/gurunathgr/.conda/envs/jhub_tensorflow/etc/jupyter\\n    - Validating...\\n      nb_conda 2.2.1 \\x1b[32mOK\\x1b[0m\\n'\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "!source activate jhub_tensorflow; conda install -y jupyter nb_conda ipykernel tensorflow matplotlib pandas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <-->Step 3: Install Jupyter kernel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installed kernelspec jhub_tensorflow in /gpfs/mira-home/gurunathgr/.local/share/jupyter/kernels/jhub_tensorflow\r\n"
     ]
    }
   ],
   "source": [
    "!source activate jhub_tensorflow; python -m ipykernel install --user --name jhub_tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### You can repeat Step 2, whenever you need to install a new module to the same kernel.\n",
    "#### !source activate jhub_tensorflow; conda install -y newmodule\n",
    "#### You can omit jupyter, nb_conda, ipykernel as you have already installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: failed with initial frozen solve. Retrying with flexible solve.\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: failed with initial frozen solve. Retrying with flexible solve.\n",
      "\n",
      "PackagesNotFoundError: The following packages are not available from current channels:\n",
      "\n",
      "  - newmodule\n",
      "\n",
      "Current channels:\n",
      "\n",
      "  - https://repo.anaconda.com/pkgs/main/linux-64\n",
      "  - https://repo.anaconda.com/pkgs/main/noarch\n",
      "  - https://repo.anaconda.com/pkgs/r/linux-64\n",
      "  - https://repo.anaconda.com/pkgs/r/noarch\n",
      "\n",
      "To search for alternate channels that may provide the conda package you're\n",
      "looking for, navigate to\n",
      "\n",
      "    https://anaconda.org\n",
      "\n",
      "and use the search bar at the top of the page.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    " !source activate jhub_tensorflow; conda install -y newmodule\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <-->To check if environment is installed correctly or activated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import tensorflow as tf\n",
    "except:\n",
    "    print('Tensorflow is not installed:', missing_modules)\n",
    "try:\n",
    "    import pandas as pd\n",
    "except:\n",
    "    print('Pandas is not installed:', missing_modules)\n",
    "try:\n",
    "    import matplotlib\n",
    "except:\n",
    "    print('Matplotlib is not installed:', missing_modules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!source activate jhub_tensorflow; pip install wurlitzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# A simple test based on the Tensorflow tutorial: https://www.tensorflow.org/tutorials\n",
    "# Run a single epoch for mnist, should take about 10 seconds.\n",
    "%load_ext wurlitzer\n",
    "import os\n",
    "os.environ[\"MKLDNN_VERBOSE\"]=\"1\"\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import datetime\n",
    "mnist = tf.keras.datasets.mnist\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "\n",
    "#dense_value=int(input(\"Enter dense value i.e integer, eg:28,45,100 :\"))\n",
    "#dropout_value=float(input(\"Enter Dropout Value  (<0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. : i.e Float, eg:0.2, 0.5:\"))\n",
    "\n",
    "\n",
    "def funt(dense_value,dropout_val):\n",
    "    #return dense_value\n",
    "    (x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "    x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "    \n",
    "    model = tf.keras.models.Sequential  ([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(dense_value, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dropout(dropout_val),\n",
    "    tf.keras.layers.Dense(10, activation=tf.nn.softmax)   ])\n",
    "   \n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    start = time.time()\n",
    "    model.fit(x_train, y_train, epochs=1)\n",
    "    runtime = time.time() - start\n",
    "    loss, acc = model.evaluate(x_test, y_test)\n",
    "    \n",
    "    # Record the versions, runtime and model metrics into a csv file.\n",
    "    record = f'{datetime.datetime.now()},{sys.version.split()[0]},{tf.__version__},{np.__version__},{loss:3f},{acc:.3f},{runtime:.3f}\\n'\n",
    "    csvfile = 'tensorflow.csv'\n",
    "    with open(csvfile, 'a') as f:\n",
    "            f.write(record)\n",
    "            \n",
    "    # Read csv file into a Pandas dataframe and print min,max, mean and standard deviation values.\n",
    "    headers = ['Date','Python_version','df_version','numpy_version','loss','accuracy','run_time']\n",
    "    df = pd.read_csv(csvfile,header=None,names=headers)\n",
    "    print('output \\n',df)\n",
    "    df.describe()\n",
    "    \n",
    "interact_manual(funt, dense_value=widgets.IntSlider(min=0,max=50,step=1,value=38),dropout_val=fixed(0.3));\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <--> Opening a log using follwing code that is generated by .csv file by running a tensorflow program. The above output is fed as a log file to program to seperate the mkldnn verbose keys into seperate file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def parse_mkldnn(filename):\n",
    "    key = 'mkldnn_verbose,'\n",
    "    f2= open(\"log.csv\",\"w+\")\n",
    "    with open(filename,'r') as f:\n",
    "        lines = f.readlines()\n",
    "    for line in lines:\n",
    "        if line.startswith(key):\n",
    "            f2.write(line)\n",
    "parse_mkldnn('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "headers =['MKL','Stage','Primitive_kind','Primitive_name','Propogation_kind','Data_type_format','Auxiliary','Problem_description','Time(ms)']\n",
    "df = pd.read_csv('log.csv',header=None,names=headers)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "output = widgets.Output()\n",
    "display(output)\n",
    "\n",
    "Primivite_kind = widgets.Button(description='Primivite_kind')\n",
    "def Primivite_kind_clicked(_):\n",
    "    with output,plt.rc_context({'axes.edgecolor':'orange', 'xtick.color':'red', 'ytick.color':'green', 'figure.facecolor':'white'}):\n",
    "        clear_output(True)\n",
    "        sumdf = df.groupby(by='Primitive_kind').sum()\n",
    "        sumdf.plot(kind='bar',title='TF1.13, Batch=4')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('tf1.13_inference.png')\n",
    "        print(\"Primivite_kind Plot Started\")\n",
    "Primivite_kind.on_click(Primivite_kind_clicked)\n",
    "\n",
    "buttons=widgets.HBox([Primivite_kind])\n",
    "widgets.VBox([buttons,output])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# A simple test based on the Tensorflow tutorial: https://www.tensorflow.org/tutorials\n",
    "# Run a single epoch for mnist, should take about 10 seconds.\n",
    "\n",
    "    \n",
    "#%load_ext wurlitzer\n",
    "import os\n",
    "os.environ[\"MKLDNN_VERBOSE\"]=\"1\"\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import datetime\n",
    "mnist = tf.keras.datasets.mnist\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "from wurlitzer import pipes\n",
    "\n",
    "\n",
    "#dense_value=int(input(\"Enter dense value i.e integer, eg:28,45,100 :\"))\n",
    "#dropout_value=float(input(\"Enter Dropout Value  (<0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. : i.e Float, eg:0.2, 0.5:\"))\n",
    "\n",
    "def funt(dense_value,dropout_val):\n",
    "    #return dense_value\n",
    "    (x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "    x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "    model = tf.keras.models.Sequential  ([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(dense_value, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dropout(dropout_val),\n",
    "    tf.keras.layers.Dense(10, activation=tf.nn.softmax)   ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    start = time.time()\n",
    "    model.fit(x_train, y_train, epochs=1)\n",
    "    runtime = time.time() - start\n",
    "    loss, acc = model.evaluate(x_test, y_test)\n",
    "\n",
    "    # Record the versions, runtime and model metrics into a csv file.\n",
    "    record = f'{datetime.datetime.now()},{sys.version.split()[0]},{tf.__version__},{np.__version__},{loss:3f},{acc:.3f},{runtime:.3f}\\n'\n",
    "    csvfile = 'tensorflow.csv'\n",
    "    with open(csvfile, 'a') as f:\n",
    "        f.write(record)\n",
    "\n",
    "    # Read csv file into a Pandas dataframe and print min,max, mean and standard deviation values.\n",
    "    headers = ['Date','Python_version','df_version','numpy_version','loss','accuracy','run_time']\n",
    "    df = pd.read_csv(csvfile,header=None,names=headers)\n",
    "    print('output \\n',df)\n",
    "    df.describe()\n",
    "    \n",
    "#funt(32,0.2)\n",
    "#interact_manual(funt, dense_value=widgets.IntSlider(min=0,max=50,step=1,value=38),dropout_val=fixed(0.3));\n",
    "\n",
    "\n",
    "with pipes() as (out, err):  \n",
    "        funt(32,0.2)\n",
    "\n",
    "#def f(dropout_value):\n",
    " #   return dropout_value\n",
    "#interact(f, dropout_value=(0,0.5));\n",
    "\n",
    "#dense_value=int(input(\"Enter dense value i.e integer, eg:28,45,100 :\"))\n",
    "#dropout_value=float(input(\"Enter Dropout Value  (<0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. : i.e Float, eg:0.2, 0.5:\"))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stdout = out.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jhub_tensorflow",
   "language": "python",
   "name": "jhub_tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
